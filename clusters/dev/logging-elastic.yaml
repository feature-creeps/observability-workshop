---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: elasticsearch
  namespace: logging
spec:
  interval: 5m
  chart:
    spec:
      chart: elasticsearch
      version: 7.17.3
      sourceRef:
        kind: HelmRepository
        name: elastic
        namespace: default
      interval: 5m
  values:
    replicas: 1
    resources:
      requests:
        cpu: "250m"
        memory: "1000Mi"
      limits:
        cpu: "500m"
        memory: "1500Mi"
    secret:
      enabled: true
      password: "changeme"
    clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"
    volumeClaimTemplate:
      resources:
        requests:
          storage: 10Gi
    lifecycle:
      postStart:
        exec:
          command:
            - bash
            - -c
            - |
              #!/bin/bash
              RETENTION=2d
              echo "applying index lifecycle management with retention period of $RETENTION days to"
              ES_URL=http://localhost:9200
              while [[ "$(curl -s -o /dev/null -w '%{http_code}\n' $ES_URL)" != "200" ]]; do sleep 1; done
              curl -XPUT "$ES_URL/_ilm/policy/logs_policy" -H 'Content-Type: application/json' -d'{"policy":{"phases":{"delete":{"min_age":"$RETENTION","actions":{"delete":{}}}}}}'
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: prometheus-elasticsearch-exporter
  namespace: logging
spec:
  interval: 5m
  chart:
    spec:
      chart: prometheus-elasticsearch-exporter
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: default
      interval: 5m
  values:
    es:
      uri: http://elasticsearch-master:9200
    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: /metrics
        prometheus.io/port: "9108"
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: elasticsearch-curator
  namespace: logging
spec:
  interval: 5m
  chart:
    spec:
      chart: elasticsearch-curator
      sourceRef:
        kind: HelmRepository
        name: lebenitza
        namespace: default
      interval: 5m
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: fluentd
  namespace: logging
spec:
  dependsOn:
    - name: elasticsearch
  interval: 5m
  chart:
    spec:
      chart: fluentd
      sourceRef:
        kind: HelmRepository
        name: fluent
        namespace: default
      interval: 5m
  values:
    podSecurityPolicy:
      enabled: false
    plugins:
      - fluent-plugin-elasticsearch-5.2.5
      - fluent-plugin-prometheus
      - fluent-plugin-rewrite-tag-filter
    fileConfigs:
      01_sources.conf: |-
        ## logs from podman
        <source>
          @type tail
          @id in_tail_container_logs
          @label @KUBERNETES
          path /var/log/containers/*.log
          pos_file /var/log/fluentd-containers.log.pos
          tag kubernetes.*
          read_from_head true
          skip_refresh_on_startup true
          <parse>
            @type multi_format
            <pattern>
              format json
              time_key time
              time_type string
              time_format "%Y-%m-%dT%H:%M:%S.%NZ"
              keep_time_key false
            </pattern>
            <pattern>
              format regexp
              expression /^(?<time>.+) (?<stream>stdout|stderr)( (.))? (?<log>.*)$/
              time_format '%Y-%m-%dT%H:%M:%S.%NZ'
              keep_time_key false
            </pattern>
          </parse>
          emit_unmatched_lines true
        </source>
      02_filters.conf: |-
        <label @KUBERNETES>
          <match kubernetes.var.log.containers.fluentd**>
            @type relabel
            @label @FLUENT_LOG
          </match>
          # <match kubernetes.var.log.containers.**_kube-system_**>
          #   @type null
          #   @id ignore_kube_system_logs
          # </match>
          <filter kubernetes.**>
            @type kubernetes_metadata
            @id filter_kube_metadata
            skip_labels false
            skip_container_metadata false
            skip_namespace_metadata true
            skip_master_url true
          </filter>

          # copy log field to message field
          <filter kubernetes.**>
            @type record_transformer
            <record>
              message ${record["log"]}
            </record>
          </filter>

          # write part of container name to service field
          <filter kubernetes.**>
            @type parser
            format /(?<service>[^_]+)/
            key_name $.kubernetes.container_name
            reserve_data true
          </filter>

          # ------------------------- split container logs ------------------------- #

          # rewrite tags based on service name
          # needs to happen within one match block as non matching results will be discarded
          # resulting in tags: domain.<service>, mongodb, frontend, trafficgen
          <match kubernetes.**>
            @type rewrite_tag_filter
            <rule>
              key service
              pattern ^(.*dima-image.+)$
              tag domain.$1
            </rule>
            <rule>
              key service
              pattern ^(.*dima-mongodb.*)$
              tag mongodb
            </rule>
            <rule>
              key service
              pattern ^(.*dima-frontend.*)$
              tag frontend
            </rule>
            <rule>
              key service
              pattern ^(.*dima-trafficgen.*)$
              tag trafficgen
            </rule>
          </match>

          # ------------------------- handle domain service logs ------------------------- #

          # parse log field as json
          <filter domain.* trafficgen>
            @type parser
            format json
            key_name log
            reserve_data true
          </filter>

          # remove tag field & log field (it is either in message now or parsed)
          <filter domain.* trafficgen>
            @type record_transformer
            remove_keys log,tag
          </filter>

          # ------------------------- split domain services' events ------------------------- #

          # reroute image* services' events to domain.<service>.event
          # field logger_name is set to event in case of event, others are set to the class
          <match domain.*>
            @type rewrite_tag_filter
            <rule>
              key logger_name
              pattern ^(.+)$
              tag ${tag}.$1
            </rule>
          </match>

          <match **>
            @type relabel
            @label @DISPATCH
          </match>
        </label>
      03_dispatch.conf: |-
        <label @DISPATCH>
          <filter **>
            @type prometheus
            <metric>
              name fluentd_input_status_num_records_total
              type counter
              desc The total number of incoming records
              <labels>
                tag ${tag}
                hostname ${hostname}
              </labels>
            </metric>
          </filter>
          <match **>
            @type relabel
            @label @OUTPUT
          </match>
        </label>
      04_outputs.conf: |-
        <label @OUTPUT>
          # ------------------------- outputs ------------------------- #

          # send all logs from fluentd itself to their own index "fluent"
          <match fluent.**>
            @type                 elasticsearch
            host                  elasticsearch-master
            port                  9200
            user                  elastic
            password              changeme
            logstash_format       true
            logstash_prefix       fluent
            logstash_dateformat   %Y.%m.%d
            include_tag_key       true
            type_name             log
            tag_key               @tag
            <buffer>
              flush_interval      1s
              flush_thread_count  2
            </buffer>
          </match>

          # send all domain events to their own index "events"
          <match domain.*.event>
            @type                 elasticsearch
            host                  elasticsearch-master
            port                  9200
            user                  elastic
            password              changeme
            logstash_format       true
            logstash_prefix       events
            logstash_dateformat   %Y.%m.%d
            include_tag_key       true
            type_name             event
            tag_key               @tag
            <buffer>
              flush_interval      1s
              flush_thread_count  2
            </buffer>
          </match>

          <match domain.*.** mongodb frontend trafficgen>
            @type copy
            # send all remaining logs from the domain services, mongodb, trafficgen and frontend to "logs"
            <store>
              @type                 elasticsearch
              host                  elasticsearch-master
              port                  9200
              user                  elastic
              password              changeme
              logstash_format       true
              logstash_prefix       logs
              logstash_dateformat   %Y.%m.%d
              include_tag_key       true
              type_name             log
              tag_key               @tag
              <buffer>
                flush_interval      1s
                flush_thread_count  2
              </buffer>
            </store>
          </match>

          # catch all for any potential unmatched logs
          <match **.**>
            @type                 elasticsearch
            host                  elasticsearch-master
            port                  9200
            user                  elastic
            password              changeme
            logstash_format       true
            logstash_prefix       unmatched
            logstash_dateformat   %Y.%m.%d
            include_tag_key       true
            type_name             log
            tag_key               @tag
            <buffer>
              flush_interval      1s
              flush_thread_count  2
            </buffer>
          </match>

        </label>
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kibana
  namespace: logging
spec:
  interval: 5m
  chart:
    spec:
      chart: kibana
      version: 7.17.3
      sourceRef:
        kind: HelmRepository
        name: elastic
        namespace: default
      interval: 5m
  values:
    kibanaConfig:
      kibana.yml: |
        elasticsearch.username: elastic
        elasticsearch.password: changeme
        server.publicBaseUrl: http://localhost:8080/kibana
        server.basePath: /kibana

    resources:
      requests:
        cpu: "100m"
        memory: "1Gi"
      limits:
        cpu: "250m"
        memory: "1Gi"
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: apm-server
  namespace: logging
spec:
  interval: 5m
  chart:
    spec:
      chart: apm-server
      version: 7.17.3
      sourceRef:
        kind: HelmRepository
        name: elastic
        namespace: default
      interval: 5m